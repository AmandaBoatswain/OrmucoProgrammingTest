{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ormuco Programming Test \n",
    "## Friday November 29th, 2019\n",
    "### Created by Amanda Boatswain Jacques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question A \n",
    "Your goal for this question is to write a program that accepts two lines (x1,x2) and (x3,x4) on the x-axis and returns whether they overlap. As an example, (1,5) and (2,6) overlaps but not (1,5) and (6,8).\n",
    "\n",
    "Assumptions for this question:\n",
    "  - There are no library restrictions\n",
    "  - A line overlaps with another if they have at least one point in common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary libraries\n",
    "import numpy as np  # numerical python\n",
    "%matplotlib inline \n",
    "\n",
    "# generate the lines\n",
    "(x1, x2) = (1, 5)\n",
    "(x3, x4) = (2, 6)\n",
    "(y) = (0, 0)  # the lines are flattened on the x-axis and therefore have a y value of 0. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can even plot the lines to see what they look like beforehand. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt # python plotting library\n",
    "\n",
    "# plot the lines to see what they look like, we will use dashed lines so that the overlap (if present) is visible.\n",
    "plt.plot((x1, x2), (y), \"r--\", (x3, x4), (y), \"b--\")\n",
    "plt.xlabel(\"x-values\")\n",
    "plt.ylabel(\"y-values\")\n",
    "plt.title(\"Two Lines\")\n",
    "plt.legend(['First Line', 'Second Line'], loc=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create a list of all the points on each of the two lines. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Points on the first line: {1, 2, 3, 4, 5}\n",
      "Points on the second line: {2, 3, 4, 5, 6}\n"
     ]
    }
   ],
   "source": [
    "# find the point coordinates of all the points on the line\n",
    "def find_coordinates(x0, xN):\n",
    "    # map the points to a list and then convert them to a set\n",
    "    coordinates = set([i for i in range(x0, xN+1)])\n",
    "    return coordinates\n",
    "\n",
    "# create point sets for the first line and the second line\n",
    "line1 = find_coordinates(x1, x2)\n",
    "line2 = find_coordinates(x3, x4)\n",
    "\n",
    "print(\"Points on the first line:\", line1)\n",
    "print(\"Points on the second line:\", line2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if the lines overlap: \n",
    "If the lines overlap, they must have at least 1 point in common. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These lines overlap at:  {2, 3, 4, 5}\n"
     ]
    }
   ],
   "source": [
    "# check if there are any common elements in the first or second line\n",
    "def check_overlap(line1, line2):\n",
    "    if (line1 & line2):\n",
    "        print(\"These lines overlap at: \", (line1&line2))\n",
    "    else:\n",
    "        print(\"These lines do not overlap.\")\n",
    "\n",
    "check_overlap(line1, line2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question B \n",
    "The goal of this question is to write a software library that accepts 2 version\n",
    "string as input and returns whether one is greater than, equal, or less than the\n",
    "other. As an example: “1.2” is greater than “1.1”. Please provide all test cases\n",
    "you could think of.\n",
    "\n",
    "Assumptions for this question:\n",
    " - There are no library restrictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will define the strings we will use to do our comparison. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the variables we will be using \n",
    "seperator = \".\" # the version levels are seperated by a period. \n",
    "string1 = \"3.4.2\"\n",
    "string2 = \"2.4.1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a version comparison method: \n",
    "Next, we will define a function to compare the two version strings. The function will loop through the various numbers in the string and compare the numbers at equal levels. If two version strings have the same number at a given level, the function will move to the subsequent level.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_versions(string1, string2, seperator= \".\"):\n",
    "    # first load the strings and then seperate the individual numbers into a list by\n",
    "    # using the split function\n",
    "    string1 = string1.split(seperator)\n",
    "    string2 = string2.split(seperator)\n",
    "\n",
    "    # loop through all the version levels\n",
    "    for level in range(0, len(string1)):\n",
    "        # if the current two levels are equal, then continue in the loop\n",
    "        if string1[level] == string2[level]:\n",
    "            continue\n",
    "            # if all the levels are the same, then return that the versions are equal\n",
    "            return print(\"Version %s is equal to version %s. \" %(seperator.join(string1), seperator.join(string2)))\n",
    "\n",
    "\n",
    "        # if the current level of string1 one is higher than string 2, return\n",
    "        # string 1\n",
    "        elif string1[level] > string2[level]:\n",
    "            return print(\"Version %s is greater than %s. \" %(seperator.join(string1), seperator.join(string2)))\n",
    "            break\n",
    "        # else, return string2\n",
    "        else:\n",
    "            return print(\"Version %s is greater than %s. \" %(seperator.join(string2), seperator.join(string1)))\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we test the function on the strings we created earlier: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version 3.4.2 is greater than 2.4.1. \n"
     ]
    }
   ],
   "source": [
    "compare_versions(string1, string2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another cool way to answer this question: Use python tuples! There is built in logic when comparing them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version 4.4.2.0 is greater than 2.4.1.3. \n"
     ]
    }
   ],
   "source": [
    "def compare_tuples(string1, string2, seperator = \".\"):\n",
    "    # convert the strings to tuples\n",
    "    string1 = tuple(string1.split(seperator))\n",
    "    string2 = tuple(string2.split(seperator))\n",
    "\n",
    "    # compare the tuples to each other and return whichever one is greater\n",
    "    if (string1 == string2):\n",
    "        return print(\"Version %s is equal to version %s. \" %(seperator.join(string1), seperator.join(string2)))\n",
    "    elif string1 > string2:\n",
    "        return print(\"Version %s is greater than %s. \" %(seperator.join(string1), seperator.join(string2)))\n",
    "    else:\n",
    "        return print(\"Version %s is greater than %s. \" %(seperator.join(string2), seperator.join(string1)))\n",
    "    \n",
    "# Define some new strings and try out the tuple method next  \n",
    "string3 = \"4.4.2.0\"\n",
    "string4 = \"2.4.1.3\"\n",
    "    \n",
    "compare_tuples(string3, string4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question C\n",
    "Dealing with network issues everyday, latency is our biggest problem. Thus, your challenge is to write a new Geo Distributed LRU (Least Recently Used) cache with time expiration. This library will be used extensively by many of our services so it needs to meet the following criteria:\n",
    "\n",
    "    1 - Simplicity. Integration needs to be dead simple.\n",
    "    2 - Resilient to network failures or crashes.\n",
    "    3 - Near real time replication of data across Geolocation. Writes need to be in real time.\n",
    "    4 - Data consistency across regions\n",
    "    5 - Locality of reference, data should almost always be available from the closest region\n",
    "    6 - Flexible Schema\n",
    "    7 - Cache can expire \n",
    "\n",
    "Assumptions for this question:\n",
    " - There are no library restrictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An least recently used (LRU) cache is a way of speeding up a program by storing \n",
    "data in memory. To implement an LRU cache we need two data structures:\n",
    "\n",
    "1- A Doubly linked list (DLL) that will serve as a Queue. In a DLL, each node has\n",
    "data and both a next and previous pointer. The maximum size of the queue  will\n",
    "have a number of nodes equal to the cache size. The most recently used reference\n",
    "will be near the front of the list(head) and the LRU reference will be placed near the\n",
    "end (tail).\n",
    "\n",
    "2- A key or hash to locate the corresponding queue entry and access its data.\n",
    "\n",
    "If we reference an item that is in memory, we will need to detach the node from the\n",
    "list and then move it to the front of the queue. If it is not in memory, we will add\n",
    "it to the front of the list and remove the LRU reference and the end of the\n",
    "queue if all nodes in the queue are already occupied. \n",
    "\n",
    "This code is primarily based on the code in this github repository: \n",
    "https://github.com/ncorbuk/Python-LRU-Cache, with some modifications made to add\n",
    "extra functionality.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we create a node object class. The node will have multiple dynamic properties including a key we can use to locate it in the cache, data (a value we want to store), a pointer to the previous node and a pointer to the node after it.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a Node class\n",
    "class Node:\n",
    "    # Create a new node, by default all values will be set to None\n",
    "    def __init__(self, key, data=None):\n",
    "        self.key = key      # access the node using its key\n",
    "        self.data = data    # data contained within the node\n",
    "        self.next = None    # set the next pointer\n",
    "        self.prev = None    # set the previous pointer\n",
    "        self.timestamp = datetime.now() # add a timestamp for time expiration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create an LRU cache class. It is primarily a DLL with a set of functions for manipulating the nodes within it. The main methods are: _ _call_ _, _insert, _remove, _modifyQueue and _verifyNode. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LRUCache:\n",
    "    cache_limit = None\n",
    "    verbose = False\n",
    "\n",
    "    def __init__(self, func, time_delta=1):\n",
    "        # set the number of nodes in the queue\n",
    "        # set the function that will be using the cache decorator\n",
    "        self.func = func\n",
    "        # dictionary (or hash) holding the items in the cache\n",
    "        self.cache = {}\n",
    "        # maximum time an item can stay in the cache before it expires in seconds\n",
    "        self.time_delta = time_delta\n",
    "\n",
    "        # create the head (first) node and tail (last) node and link them together\n",
    "        self.head = Node(key=0, data=0)\n",
    "        self.tail = Node(key=0, data=0)\n",
    "        self.head.next = self.tail\n",
    "        self.tail.prev = self.head\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        \n",
    "        \"\"\"We want to treat this instance of a class (aka Objects), as if if were a function: to achieve this we \n",
    "        pass them to other methods/functions and call them. In order to achieve this, the __call__ class function \n",
    "        has to be specialized. We want this function to be used as a decorator for another function. \"\"\"\n",
    "        \n",
    "        # if the answer is in the cache, pull results from the queue and place the\n",
    "        # newly accessed value at the head\n",
    "        if args in self.cache:\n",
    "            self._modifyQueue(args) # place new value at list head\n",
    "            # print the cache to screen \n",
    "            if self.verbose == True: \n",
    "                print(f'Cached...{args}\\n result: {self.cache[args]}\\nCache: {self.cache}')\n",
    "                # return the result saved in the cache \n",
    "            return self.cache[args]\n",
    "\n",
    "        # if the cache limit is exceeded:\n",
    "        if self.cache_limit is not None:\n",
    "            if len(self.cache) >= self.cache_limit:\n",
    "                #remove the LRU item from the queue\n",
    "                next = self.head.next\n",
    "                self._remove(next)\n",
    "                del self.cache[next.key]\n",
    "\n",
    "        # if the value is not stored in the cache, compute the answer and store it\n",
    "        result = self.func(*args, **kwargs)\n",
    "        # create a node with the new argument and its data\n",
    "        node = Node(key=args, data=result)\n",
    "        self.cache[args] = result\n",
    "        # add to the queue\n",
    "        self._insert(node)\n",
    "        if self.verbose == True: \n",
    "            print(f'Result {result} added to cache on {node.timestamp.strftime(\"%b%d%Y %H:%M:%S\")}\\nCache: {self.cache}')\n",
    "        return result\n",
    "\n",
    "    \"\"\" Node manipulation functions \"\"\"\n",
    "    # insert the new node at the head of the list\n",
    "    def _insert(self, node):\n",
    "        # retrieve the node before the head, and set the node after it is as the\n",
    "        # current node\n",
    "        previous = self.tail.prev\n",
    "        previous.next = node\n",
    "        # link the node to the tail\n",
    "        self.tail.prev = node\n",
    "        # place the most recent node at the head before the previous node\n",
    "        node.prev = previous\n",
    "        node.next = self.tail\n",
    "\n",
    "    # remove a node from the queue\n",
    "    def _remove(self, node):\n",
    "        # retrieve the node before and the node after\n",
    "        previous = node.prev\n",
    "        next = node.next\n",
    "        # set the previous node to skip over to the next node (removing the one\n",
    "        # in between), and vice versa\n",
    "        previous.next = next\n",
    "        next.prev = previous\n",
    "\n",
    "    # if the result of the passed args is already in the queue, move it to the\n",
    "    # head of the cache\n",
    "    def _modifyQueue(self, args):\n",
    "        # get the current head\n",
    "        current = self.head\n",
    "        while True:\n",
    "            # check to see if that result exists in the queue\n",
    "            if current.key == args:\n",
    "                node = current\n",
    "                # remove the node from its current position and then add it to the head\n",
    "                self._remove(node)\n",
    "                self._insert(node)\n",
    "\n",
    "                # update the positions of the values in the cache\n",
    "                del self.cache[node.key]\n",
    "                self.cache[node.key] = node.data\n",
    "\n",
    "                break\n",
    "\n",
    "            else:\n",
    "                # check the next node until a match is found\n",
    "                current = current.next\n",
    "                # check to see if the node has expired\n",
    "                self._verifyNode(current)\n",
    "\n",
    "    def _verifyNode(self, node):\n",
    "        now = datetime.now()\n",
    "        elapsed_time = (now-node.timestamp).seconds\n",
    "        if elapsed_time > self.time_delta:\n",
    "            if self.verbose == True:\n",
    "                print(f\"Warning: Node @ ({node.key}, {node.data}) has expired!\")\n",
    "        ### NOTE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE: Ideally we would add some kind of code to remove the node here, but I unfortunately couldn't get it to work without breaking the entire list..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can witness the LRU cache in action. We can define two functions that will be used repeatedly, and a list of arguments we would like to pass. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries we will use \n",
    "import time \n",
    "from datetime import datetime \n",
    "import numpy as np \n",
    "# Note: we could also save the Node and LRUCache class in a seperate file and import them using from LRUCache import *   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a slow function that we can modify by adding the cache. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function that returns the square of a number\n",
    "def function1(num):\n",
    "    print(f\"Computing the square of {num}...\")\n",
    "    time.sleep(1)\n",
    "    return num*num "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we can create a list of random values to input as arguments to the functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Argument list:  [7, 5, 0, 5, 7, 9, 2, 4, 4, 0, 6, 6, 8, 5, 7, 5, 2, 0, 6, 0]\n"
     ]
    }
   ],
   "source": [
    "args = []\n",
    "# generate 20 random numbers between 0 and 10 and append them to a list \n",
    "for i in range(0, 20):\n",
    "    num = np.random.randint(0, 10)\n",
    "    args.append(num)\n",
    "\n",
    "print(\"Argument list: \", args)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the square of 7...\n",
      "49\n",
      "Computing the square of 5...\n",
      "25\n",
      "Computing the square of 0...\n",
      "0\n",
      "Computing the square of 5...\n",
      "25\n",
      "Computing the square of 7...\n",
      "49\n",
      "Computing the square of 9...\n",
      "81\n",
      "Computing the square of 2...\n",
      "4\n",
      "Computing the square of 4...\n",
      "16\n",
      "Computing the square of 4...\n",
      "16\n",
      "Computing the square of 0...\n",
      "0\n",
      "Computing the square of 6...\n",
      "36\n",
      "Computing the square of 6...\n",
      "36\n",
      "Computing the square of 8...\n",
      "64\n",
      "Computing the square of 5...\n",
      "25\n",
      "Computing the square of 7...\n",
      "49\n",
      "Computing the square of 5...\n",
      "25\n",
      "Computing the square of 2...\n",
      "4\n",
      "Computing the square of 0...\n",
      "0\n",
      "Computing the square of 6...\n",
      "36\n",
      "Computing the square of 0...\n",
      "0\n",
      "Time elapsed:  20\n"
     ]
    }
   ],
   "source": [
    "# time the use of the function without the LRU cache \n",
    "start_time = datetime.now()\n",
    "for i in range(len(args)):\n",
    "    print(function1(args[i]))\n",
    "    \n",
    "delta_time = (datetime.now()-start_time).seconds\n",
    "# elapsed time should follow 0(n) since we are doing n operations in a sequence\n",
    "print(\"Time elapsed: \", delta_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now do the same thing but while adding the LRU cache: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the square of 7...\n",
      "49\n",
      "Computing the square of 5...\n",
      "25\n",
      "Computing the square of 0...\n",
      "0\n",
      "25\n",
      "49\n",
      "Computing the square of 9...\n",
      "81\n",
      "Computing the square of 2...\n",
      "4\n",
      "Computing the square of 4...\n",
      "16\n",
      "16\n",
      "0\n",
      "Computing the square of 6...\n",
      "36\n",
      "36\n",
      "Computing the square of 8...\n",
      "64\n",
      "25\n",
      "49\n",
      "25\n",
      "4\n",
      "0\n",
      "36\n",
      "0\n",
      "Time elapsed:  8\n"
     ]
    }
   ],
   "source": [
    "# set the cache limit, default limit is None. As we increase the size of the cache, the speed will also increase \n",
    "# but will require more memory storage \n",
    "LRUCache.cache_limit = 10 \n",
    "\n",
    "@LRUCache\n",
    "def function1(num):\n",
    "    print(f\"Computing the square of {num}...\")\n",
    "    time.sleep(1)\n",
    "    return num*num \n",
    "\n",
    "# time the use of the function with the LRU cache \n",
    "start_time = datetime.now()\n",
    "for i in range(len(args)):\n",
    "    print(function1(args[i]))\n",
    "    \n",
    "delta_time = (datetime.now()-start_time).seconds\n",
    "print(\"Time elapsed: \", delta_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
